# -*- coding: utf-8 -*-
"""Untitled7.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/15ChGDWzUuAwM-15ps_lQJ0P0AopnKmYl
"""

import pandas as pd
import requests
from bs4 import BeautifulSoup
import numpy as np
import re
import json
import pymongo
from pymongo import MongoClient


#---------- Scraping ----------
"""En esta parte del codigo se realizara el scraping"""

urls = ['https://www.imdb.com/search/title/?groups=top_1000&count=250&sort=user_rating,asc',
        'https://www.imdb.com/search/title/?groups=top_1000&count=250&sort=runtime,asc',
        'https://www.imdb.com/search/title/?groups=top_1000&count=250&sort=year,desc',
        'https://www.imdb.com/search/title/?groups=top_1000&count=250&sort=boxoffice_gross_us,desc',
        'https://www.imdb.com/search/title/?groups=top_1000&count=250',
        'https://www.imdb.com/search/title/?groups=top_1000&count=250&sort=moviemeter,desc']
movies = []
contador = 0

# regex para quitar numero de nombre
patron = re.compile(r'^\d+\.')

# funcion para aplicar regex al nombre de pelicula
def quitar_numero(nombre):
      return patron.sub('', nombre)

# funcion para acceder a metadatos
def convertir_a_enlace_de_reviews(enlace_original):
      match = re.search(r'([^/]+)/?$', enlace_original)
      if match:
          ultimo_slash = match.group(1)
          enlace_reviews = f"{enlace_original}{ultimo_slash}/reviews"
          return enlace_reviews
      else:
          return None

def convertir_a_numero(abreviado):
      # Diccionario para mapear sufijos a factores
      sufijo_factor = {'K': 1e3, 'M': 1e6}

      # Extraer el sufijo y la parte numérica
      sufijo = abreviado[-1]
      numero = float(abreviado[:-1])

      # Multiplicar por el factor correspondiente y devolver el resultado como entero
      return int(numero * sufijo_factor.get(sufijo, 1))

def convertir_a_minutos(duracion):
      partes = duracion.split()  # Dividir la duración en partes (horas y minutos)
      minutos_totales = 0

      for parte in partes:
          if parte.endswith('h'):  # Si la parte es en horas
              horas = int(parte[:-1])  # Obtener el número de horas
              minutos_totales += horas * 60  # Convertir horas a minutos
          elif parte.endswith('m'):  # Si la parte es en minutos
              minutos = int(parte[:-1])  # Obtener el número de minutos
              minutos_totales += minutos  # Agregar los minutos al total

      return minutos_totales

for url in urls:
    contador += 1
    headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/114.0.0.0 Safari/537.36'}
    response = requests.get(url, headers=headers)
    soup = BeautifulSoup(response.content, 'html.parser')

    #storing the meaningfull required data in the variable
    movie_data = soup.findAll('li', attrs= {'class': 'ipc-metadata-list-summary-item'})

    contadorkk = 0

    for store in movie_data:
            movie = {}

            name = store.div.h3.text
            name = quitar_numero(name)
            movie['name'] = name

            reference = store.find('a', class_ = "ipc-title-link-wrapper")
            href = reference.get('href')

            year_of_release = store.findAll('span', class_ = "sc-b189961a-8 kLaxqf dli-title-metadata-item")[0].text
            movie['year'] = year_of_release

            duration = store.findAll('span', class_ = "sc-b189961a-8 kLaxqf dli-title-metadata-item")[1].text
            duration = convertir_a_minutos(duration)
            movie['duration'] = duration

            try:
                ratings = store.findAll('span', class_="sc-b189961a-8 kLaxqf dli-title-metadata-item")[2].text
                movie['ratings'] = ratings
            except IndexError:
                movie['ratings'] = None

            calification_popularity = store.find('span', class_ = "ipc-rating-star ipc-rating-star--base ipc-rating-star--imdb ratingGroup--imdb-rating").text
            calification = calification_popularity[:3]
            popularity = calification_popularity[5:-1]
            popularity = convertir_a_numero(popularity)

            movie['calification'] = calification
            movie['popularity'] = popularity

            metacritic = 0  # iniciamos metacritic como None ya que hay valores nulos
            try:
                metacritic = store.find('span', class_="sc-b0901df4-0 bcQdDJ metacritic-score-box").text
            except AttributeError:
                pass

            movie['metacritic_score'] = metacritic

            description = store.find('div', class_ = "ipc-html-content-inner-div").text
            movie['description'] = description

            movies.append(movie)

            # accedemos a cada pelicula individualmente para poder acceder a mas datos
            additional_url = "https://www.imdb.com" + href

            headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/114.0.0.0 Safari/537.36'}
            response = requests.get(additional_url, headers=headers)
            soup = BeautifulSoup(response.content, 'html.parser')

            list_actors = soup.findAll('a', class_ = "sc-bfec09a1-1 gCQkeh")
            actors = []
            for actor in list_actors:
                actor = actor.text
                actors.append(actor)
                movie['Actors'] = actors

            director = soup.findAll('a', class_ = "ipc-metadata-list-item__list-content-item ipc-metadata-list-item__list-content-item--link")[0].text
            movie['Director'] = director

            genres = soup.findAll('div', class_ = "ipc-chip-list__scroller")[0].text
            genres = re.findall('[A-Z][^A-Z]*', genres)
            movie['Genres'] = genres

            # accedemos al link de sus respectivas reviews
            reviews_url = re.sub(r'/(?=[^/]*$)', "/reviews", additional_url)

            headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/114.0.0.0 Safari/537.36'}
            response = requests.get(reviews_url, headers=headers)
            soup = BeautifulSoup(response.content, 'html.parser')

            list_review = soup.findAll('div', class_ = "text show-more__control")
            reviews = []
            max_films = 0
            for review in list_review:
                if max_films < 10:
                    review = review.text
                    reviews.append(review)
                    movie['Reviews'] = reviews
                    max_films += 1
                else:
                  continue

            print("Url:", contador ,"----> Progreso:", contadorkk, "/250")
            contadorkk += 1


# para guardar los datos como json
json_data = json.dumps(movies, indent=4)

with open('movies_data.json', 'w') as f:
    f.write(json_data)

print("Datos almacenados en 'movies_data.json'")


#---------- MongoDB ----------
"""En esta parte del codigo se realizara la inserccion de los datos en MongoDB"""

client = MongoClient('mongodb+srv://aris:1234@cluster0.5ss2jng.mongodb.net/?retryWrites=true&w=majority&appName=Cluster0')

db = client['SGRP_BDNR']
collection = db['movies']

# Lee datos del json
with open('movies_data.json') as f:
    movies_data = json.load(f)

contador = 0

for movie in movies_data:
    # Busca si ya existe la película
    existing_movie = collection.find_one({"name": movie["name"]})
    if existing_movie:
        # Si existe, actualiza los datos
        collection.update_one({"_id": existing_movie["_id"]}, {"$set": movie})
        #print(f"La película{movie['name']} se ha actualizado en la base de datos.")
    else:
        # Si no existe, la inserta como nueva
        collection.insert_one(movie)
        #print(f"La película{movie['name']} se ha añadido a la base de datos.")
    contador += 1
    print("Progreso:", contador, "/1500")

print("Proceso completado.")
print("Datos almacenados en MongoDB correctamente.")